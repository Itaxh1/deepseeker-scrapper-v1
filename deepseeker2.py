import streamlit as st
import requests
import urllib.parse
import concurrent.futures
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.vectorstores import InMemoryVectorStore
from langchain_ollama import OllamaEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from langchain_ollama.llms import OllamaLLM

STACKOVERFLOW_API = "https://api.stackexchange.com/2.3/search/advanced"
MEDIUM_SEARCH_URL = "https://medium.com/search?q={query}"

template = """
You are an AI assistant helping users with coding questions. Below is the response generated by DeepSeek followed by relevant answers from Stack Overflow and Medium.

## DeepSeek Response:
{deepseek_response}

## Stack Overflow Answers:
{stackoverflow_answers}

## Medium Blog Posts:
{medium_answers}
"""

embeddings = OllamaEmbeddings(model="deepseek-r1:1.5b")
vector_store = InMemoryVectorStore(embeddings)
model = OllamaLLM(model="deepseek-r1:1.5b")

def refine_search_query(question):
    """Uses DeepSeek to generate a concise search query (max 300 chars) for Stack Overflow and Medium."""
    prompt = ChatPromptTemplate.from_template("""
    Given the following coding question:
    {question}
    
    Generate the best possible search query under 300 characters, optimized for finding relevant answers on Stack Overflow and Medium.
    Return only the query without explanations, examples, or any extra text.
    """)
    chain = prompt | model
    response = chain.invoke({"question": question}).strip()
    
    # Extract the first valid line that is not a <think> tag or explanation
    refined_query = response.split("\n")[0][:300]
    if "<think>" in refined_query.lower() or len(refined_query) < 5:
        refined_query = question  # Use the original question if DeepSeek fails
    
    return refined_query

def fetch_stackoverflow_answers(query):
    params = {
        "order": "desc",
        "sort": "relevance",
        "q": query,
        "site": "stackoverflow",
        "filter": "!9_bDE(fI5",
        "pagesize": 5  # Limit results to 5
    }
    response = requests.get(STACKOVERFLOW_API, params=params)
    if response.status_code == 200:
        items = response.json().get("items", [])
        answers = []
        for i, item in enumerate(items[:5], start=1):  # Fetch top 5 answers
            link = item.get("link", "")
            title = item.get("title", "")
            answers.append(f"{i}. [{title}]({link})")
        return "\n".join(answers) if answers else "No relevant Stack Overflow answers found."
    return "Failed to fetch Stack Overflow answers."

def fetch_medium_answers(query):
    search_url = MEDIUM_SEARCH_URL.format(query=urllib.parse.quote_plus(query))
    return f"1. [Click here to see relevant Medium blog posts]({search_url})"

def generate_deepseek_response(question):
    prompt = ChatPromptTemplate.from_template("Question: {question}\nAnswer:")
    chain = prompt | model
    return chain.invoke({"question": question})

st.title("DeepSeeker with Smart Stack Overflow & Medium Search")
question = st.text_input("Enter your coding question:")

if question:
    st.chat_message("user").write(question)
    with concurrent.futures.ThreadPoolExecutor() as executor:
        future_deepseek = executor.submit(generate_deepseek_response, question)
        future_query = executor.submit(refine_search_query, question)
        refined_query = future_query.result()
        print("Refined Search Query:", refined_query)  # Debugging output
        
        future_stackoverflow = executor.submit(fetch_stackoverflow_answers, refined_query)
        future_medium = executor.submit(fetch_medium_answers, refined_query)
        
        deepseek_response = future_deepseek.result()
        stackoverflow_answers = future_stackoverflow.result()
        medium_answers = future_medium.result()
    
    final_response = template.format(deepseek_response=deepseek_response, stackoverflow_answers=stackoverflow_answers, medium_answers=medium_answers)
    st.chat_message("assistant").write(final_response)
