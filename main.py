import os
import streamlit as st
import requests
import urllib.parse
import concurrent.futures
import time
from openai import OpenAI
import logging
from dotenv import load_dotenv
load_dotenv()

OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")
st.write("API key loaded:", OPENROUTER_API_KEY is not None)

def get_secret(key, default=""):
    """Get secret from environment variable or fallback to st.secrets."""
    return os.getenv(key) or st.secrets.get(key, default)

# Initialize OpenAI client with OpenRouter using env-aware API key
client = OpenAI(
    base_url="https://openrouter.ai/api/v1",
    api_key=get_secret("OPENROUTER_API_KEY"),
)

# Constants with optimized parameters
STACKOVERFLOW_API = "https://api.stackexchange.com/2.3/search/advanced"
MEDIUM_SEARCH_URL = "https://medium.com/search?q={query}"
STACKOVERFLOW_CACHE_EXPIRY = 3600  # 1 hour cache
REQUEST_TIMEOUT = 5  # Reduced timeout from 10 to 5 seconds

template = """
You are an AI assistant helping users with coding questions. Below is the response generated by DeepSeek followed by relevant answers from Stack Overflow and Medium.

## DeepSeek Response:
{deepseek_response}

## Stack Overflow Answers:
{stackoverflow_answers}

## Medium Blog Posts:
{medium_answers}
"""

# Prepare headers with env-aware site info
extra_headers = {
    "HTTP-Referer": get_secret("SITE_URL", "https://localhost"),
    "X-Title": get_secret("SITE_NAME", "DeepSeek Coding Assistant"),
}

def refine_search_query(question):
    """Uses DeepSeek to generate a concise search query (max 300 chars) for Stack Overflow and Medium."""
    try:
        completion = client.chat.completions.create(
            extra_headers=extra_headers,
            model="deepseek/deepseek-r1-0528:free",
            messages=[
                {
                    "role": "system",
                    "content": "Given a coding question, generate the best possible search query under 300 characters, optimized for Stack Overflow and Medium. Return only the query."
                },
                {
                    "role": "user",
                    "content": question
                }
            ],
            max_tokens=100
        )
        
        refined_query = completion.choices[0].message.content.strip()[:300]
        if len(refined_query) < 5:
            return question  # Fallback to original question if response is too short
        
        return refined_query
    except Exception as e:
        st.error(f"Error refining search query: {str(e)}")
        return question  # Fallback to original question on error

@st.cache_data(ttl=STACKOVERFLOW_CACHE_EXPIRY, show_spinner=False)
def fetch_stackoverflow_answers(query):
    """Optimized Stack Overflow answer fetcher with caching and performance tracking."""
    start_time = time.time()
    
    try:
        # Optimized params
        params = {
            "order": "desc",
            "sort": "relevance",
            "q": query,
            "site": "stackoverflow",
            "filter": "!nKzQUR693x",  # Lightweight filter
            "pagesize": 3,  # Reduced from 5 to 3
            "answers": 1,  # Only questions with answers
            "accepted": True  # Prioritize accepted answers
        }
        
        response = requests.get(
            STACKOVERFLOW_API,
            params=params,
            timeout=REQUEST_TIMEOUT
        )
        response.raise_for_status()
        
        items = response.json().get("items", [])
        
        if not items:
            return "No relevant Stack Overflow answers found."
        
        answers = [
            f"{i}. [{item.get('title', 'No title')}]({item.get('link', '')})"
            for i, item in enumerate(items[:3], 1)
        ]
        
        return "\n".join(answers)
        
    except requests.exceptions.Timeout:
        return "Stack Overflow search timed out. Please try again."
    except requests.exceptions.RequestException as e:
        st.error(f"Stack Overflow API error: {str(e)}")
        return "Failed to fetch Stack Overflow answers."

def fetch_medium_answers(query):
    """Optimized Medium answer fetcher with basic error handling."""
    try:
        encoded_query = urllib.parse.quote(query)
        search_url = MEDIUM_SEARCH_URL.format(query=encoded_query)
        return f"1. [Search Medium for: {query}]({search_url})"
    except Exception as e:
        st.error(f"Medium URL generation error: {str(e)}")
        return "Failed to generate Medium search link"

def generate_deepseek_response(question):
    try:
        completion = client.chat.completions.create(
            extra_headers=extra_headers,
            model="deepseek/deepseek-r1-0528:free",
            messages=[
                {
                    "role": "system",
                    "content": "You are an expert AI assistant helping with coding questions. Provide clear, concise, and accurate answers."
                },
                {
                    "role": "user",
                    "content": question
                }
            ],
            temperature=0.7,
            max_tokens=1000
        )
        return completion.choices[0].message.content
    except Exception as e:
        st.error(f"Error generating DeepSeek response: {str(e)}")
        return "Sorry, I couldn't generate a response. Please try again."

# Streamlit UI
st.title("🔍 DeepSeek Coding Assistant")
st.caption("Get AI-powered coding help with relevant Stack Overflow and Medium results")

question = st.text_input("Enter your coding question:", placeholder="e.g., How to fix Python TypeError?")

if st.button("Get Answer") and question:
    start_time = time.time()
    
    with st.spinner("Searching for the best answer..."):
        with concurrent.futures.ThreadPoolExecutor() as executor:
            # Submit all tasks in parallel
            future_deepseek = executor.submit(generate_deepseek_response, question)
            future_query = executor.submit(refine_search_query, question)
            future_stackoverflow = executor.submit(fetch_stackoverflow_answers, question)  # Using original question for cache efficiency
            future_medium = executor.submit(fetch_medium_answers, question)
            
            # Get results
            refined_query = future_query.result()
            deepseek_response = future_deepseek.result()
            stackoverflow_answers = future_stackoverflow.result()
            medium_answers = future_medium.result()
            
            # Store for debugging
            st.session_state['last_query'] = refined_query
            st.session_state['search_time'] = time.time() - start_time
        
        # Format final response
        final_response = template.format(
            deepseek_response=deepseek_response,
            stackoverflow_answers=stackoverflow_answers,
            medium_answers=medium_answers
        )
        
        # Display results
        st.chat_message("assistant").write(final_response)
        
        # Debug section (collapsible)
        with st.expander("Performance Details"):
            st.write(f"**Total search time:** {st.session_state['search_time']:.2f} seconds")
            st.write(f"**Refined Search Query:** {refined_query}")
            st.write(f"**Stack Overflow Results:** {stackoverflow_answers}")
            st.write(f"**Medium Results:** {medium_answers}")
